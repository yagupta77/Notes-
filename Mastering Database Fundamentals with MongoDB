# Notes-  Mastering Database Fundamentals with MongoDB


 1.Introduction to Database and DBMS 

 A Database is a structured collection of data that allows efficient storage, access, and management.

Why Use a Database
    -> Organize and retrieve data efficiently
    -> Ensure data security and integrity
    -> Support multiple users
    -> Handle large data volumes
    -> Provide backup and recovery

ISAM (Indexed Sequential Access Method)
    Early method of storing data using indexes for faster sequential access.

DBMS (Database Management System)
    Software that manages databases and handles operations like Create, Read, Update, Delete (CRUD).
    Examples: MySQL, MongoDB, PostgreSQL.

Components of a Database System
    -> DB Server: Handles client requests and manages data (runs as a TCP server).
    -> DB Client: Connects to the server.
        -> GUI Clients: MySQL Workbench, MongoDB Compass
        -> Terminal Clients: mysql, mongo
        -> Drivers: Used in apps (e.g., MySQL Node.js driver)

    -> Storage Engine: Stores data on disk (e.g., InnoDB, WiredTiger)

Communication Protocols
    Databases use their own protocols over TCP to talk to clients:
        -> MySQL Protocol
        -> MongoDB Wire Protocol



 2. Type Of DataBases

Relational Database (RDBMS)

    -> Stores data in tables, like Excel sheets.
    -> Data is organized in rows and columns.
    -> You must define the structure (schema) before adding data.
    -> Good at handling linked data (e.g., customers and their orders).
    -> Very accurate and reliable â€“ used in banking, business apps.
    -> Needs powerful machines to scale.
    -> Examples: MySQL, PostgreSQL.

Non-Relational Database (NoSQL)

    -> Stores data in a more flexible way â€“ like JSON files, key-value pairs, or graphs.
    -> You donâ€™t need to define a fixed structure before adding data.
    -> Good for fast-changing or large amounts of data.
    -> Easier to scale across many computers.
    -> Used in apps like social media, real-time chats, analytics.
    -> Examples: MongoDB, Redis, Cassandra.

In Simple Terms:

    -> Use Relational DB when your data is organized and linked (like school or bank data).
    -> Use Non-Relational DB when your data is messy, big, or changes often (like social media posts or logs).


3. Introduction Of MongoDB

**MongoDB** is a popular open-source NoSQL database that stores data in a flexible, document-oriented format. It is designed to handle large-scale, high-performance applications while offering scalability, flexibility, and ease of use.

## What does the term Mongo mean?
The term "Mongo" in MongoDB is derived from the word "humongous", which reflects the database's ability to handle large volumes of data. MongoDB is designed to manage massive datasets and scale horizontally, making it suitable for modern applications that require handling extensive amounts of information efficiently.


## Key Features of MongoDB

1. **Document-Oriented**: 
   - Stores data in JSON-like BSON (Binary JSON) documents, allowing for hierarchical data storage and flexible schemas.

2. **Schema-Less**:
   - No predefined schema is required, enabling developers to store data with varying structures.

3. **Scalability**:
   - Supports horizontal scaling through sharding, making it suitable for applications with large datasets and high traffic.

4. **Rich Query Language**:
   - Offers a powerful query language (MQL) to perform CRUD operations, aggregations, and more.

5. **Indexing**:
   - Provides efficient indexing to enhance query performance.

6. **Replication**:
   - Ensures high availability and fault tolerance through replica sets.

## Use Cases of MongoDB

- Real-time analytics and big data applications.
- Content management systems (CMS) and blogs.
- IoT and sensor data storage.
- E-commerce platforms and product catalogs.
- Mobile and web applications with dynamic data requirements.

## Popular Integrations

MongoDB integrates seamlessly with modern programming languages and frameworks like:
- Node.js
- Python (Django, Flask)
- Java (Spring)
- Express.js (via Mongoose)

## Why Use MongoDB?

MongoDBâ€™s flexible data model, scalability, and rich feature set make it an excellent choice for modern, high-performance applications that require handling unstructured or semi-structured data efficiently.


 5.Mongo Shell 

    It is a node REPL.
    Since it is a node REPL, we can do all the operations of NodeJS.

    mongo shell uses full node.exe but has modified it for handling database operations.

    Difference between node REPL and mongoSh REPL

    Node REPL:
        1. Undefined is return if there is no return value.
        2. Does not highlights the code.
        3. In case of promise, it returns the full promise object.
        4. We cannot redeclare, redefine a const variable.
        5. await can de used in global space.
        6. Npm can be accessed and used. 
        7. Don't have extra commands for handling databases. 
        8. process.exit() is used for exiting.

    MongoSH REPL:
        1. Newline character (Empty line) is returned if there is no return value.
        2. Highlights the code.
        3. In case of promise, it returns resolve value of promise, Highlights the Error in case of rejection.
        4. We can redeclare, redefine a const variable.
        5. await cannot be used in global space. ( use async function )
        6. NPM cannot be accessed.
        7. Have extra commands for handling databases. 
        8. exit command use to exit the shell

Key points:

The Complete Picture: MongoDB's Developer-Friendly Design
1. The Core Problem: The Mental Switch
Developers had to constantly switch between two mindsets:
Application Code: Thinking in objects, dictionaries, and lists (e.g., {name: "Alice"}).
Database Queries: Thinking in a different language like SQL (INSERT INTO users...).
This context switch was inefficient and frustrating.

2. The Vision: One Unified World
MongoDBâ€™s goal was to eliminate this switch. Since modern apps use JSON-like data, MongoDB stores data in the same wayâ€”as JSON-like documents (BSON). This means the data in your database looks identical to the data in your code.

3. The Perfect Example: The MongoDB Shell (mongosh)
The shell is the purest expression of this vision. Itâ€™s a JavaScript environment where you interact with the database using plain JavaScriptâ€”no new language to learn.

javascript
// This is just JavaScript! No mental switch.
db.users.insertOne({name: "Alice"})
4. How This Works for Every Language (Python, Java, etc.)
The seamless experience doesn't end with JavaScript. For any other language, MongoDB provides a Driver (e.g., pymongo for Python).

The Driverâ€™s Job: To mimic the MongoDB shellâ€™s API in the style of its native language.

In Practice: This means you write commands in Python or Java that look and feel almost identical to the shell commands.

Python Example:

python
# This is Python code, but the style is inspired by the JS shell.
db.users.insert_one({"name": "Alice"})
5. The Magic Behind the Scenes: Universal Translation
Whether you use the JavaScript shell, a Python driver, or a Java driver, they all do the same thing:

They take your native code (JS objects, Python dicts, Java Maps).

They translate it into a universal language called BSON.

They send this BSON over the network to the MongoDB server using the Wire Protocol.

The server doesn't care what language you used. It only understands BSON. The driver and shell handle all the translation for you, making the experience consistent everywhere.

6. Why the Shell Feels Like Node.js
To be a powerful tool, the shell needed more than just variables and loopsâ€”it needed file operations, networking, and timers. Instead of building this from scratch, MongoDB used Node.js as a blueprint. The shell is built on the same technology (V8 engine) and offers familiar APIs (like require('fs')), but with custom, secure versions to keep your database safe.

In a Nutshell:
MongoDB gives you a consistent way to work with your database, no matter your programming language.

For JavaScript developers, the mongosh shell provides a native, powerful environment.

For all other developers, official drivers provide the same simple, intuitive experience tailored to their language.

The result: You always get to think in your code's native data structures, completely eliminating the old, frustrating context switch.


7. Installing and Understanding MongoDB Server

   Clients to Connect to MongoDB Server

    -> MongoDB Compass: Official GUI client for interacting with the server.
    -> MongoDB VS Code Extension:
        Acts as another client to connect to the server.
        Often provides more detailed views and features than Compass (like document preview, schema, and queries within the editor).

   MongoDB Server Summary

    -> MongoDB Server is mainly built in C++, along with other languages.
    -> Port: It uses a fixed default port 27017 (other ports won't work unless configured).
    -> On installation, MongoDB defaults to a virtual test database, which isnâ€™t created on disk until data is stored.
    -> You can view available databases with:
        show("databases") or its short form show dbs.


8.Fundamentals of MongoDB: Databases, Collections, and Documents

Fundamentals of MongoDB

    MongoDB Server by default creates these databases:
    (We should not manipulate them) 
        -> admin
        -> config
        -> local

    Database:
        -> The main entity for our app is Database. 
        -> It can have multiple collections
        -> Drop database means DELETE Database.
        -> It is only created when we have atleast one collection & one document.

    Collections:
        -> It is a part of Database.
        -> It can have multiple documents.
        -> It is not actually array, but like array.
        -> Drop collection means DELETE Collection.
    
    Documents:
        -> It is JSON Object, which stores the actual data.

    Understandig this through making storageApp DB:
        Main Entity(DataBase) -> StorageAppDB
        Collection -> directoriesCollection.json
        Document -> Each Directory Object

    Connections:
        -> It means a connection between the client and the server.
        -> There can be different (user) connections on a single server.

    Commands:
        -> use("<Database Name>") OR use <Database Name>
            If the database it not-existing. It create a non-existence database. And use it
        -> show collections
            It will show all the existing collections.


 9.Create Operation in MongoDB

    Create Operation through GUI:
        -> Click '+' on Connection
        -> Enter DB name, Collection name.
        -> For creating document:
            -> Click on "Add Data" in Collection.
            -> You have 2 Options (import JSON or insert document)
            -> Write your data in JSON Format.

        -> It will store in the main Server.

    Create Operation through Shell:
        -> use <Database Name>
        -> db.<CollectionName>.insertOne(<Document>)
            It will create a collection and insert the data(document) in it.

        -> db.<CollectionName>.insertOne(<Documents>)
            It will create a collection and insert all the data(documents) in it.

    Access it thorugh Shell:
        -> db represent to the current database used.
        -> we can do db.<collectionName>.find()
            It will show all the available documents in it.


10. Read Operation in MongoDB

    Read Operation in MongoDB

    -> db represent to the current database used.
    -> we can do db.<collectionName>.find()
        It will show all the available documents in it.
        It returns a cursor, it is like an array
    
    -> For finding specific documents we can pass an object in find()
        db.<collectionName>.find({ user: "23" })

    -> Just like find we also have findOne method,
        Which returns only the first match (as Object not cursor).
        db.<collectionName>.findOne({ user: "23" })

    -> If we want to find document in more depth, use configuration object:
        db.<collectionName>.findOne({ user: {$gt : 2} })

        $gt -> greaterThan
        $gte -> greaterThanEqualTo
        $lt -> LessThan
        $lte -> LessThanEqualTo

11. Inspecting MongoDB Data Packets in Wireshark

      Behinds the Scenes Mongo Data Packets

    -> MongoDB Protocol is built on top of TCP.
    -> It make a three way TCP handshake.
    -> Send request-response in every 3-5 Secs for checking it connection is alive or not.
    -> For every DB call(Operation) a request is send to server.
    -> DB calls in Shell is Synchronous


    12. Update Operation in MongoDB
   
        Update Operation in MongoDB

    -> For updating a document we need to first find it.
    -> db.<Collection>.updateOne(findingObj, {$set: updateObj});

        Eg.
        db.expenses.updateOne({ title: "Grocery" }, {$set: { value: "20" }});

    -> db.<Collection>.replaceOne(findingObj, replaceObj);
        It will replace the whole object
    
    -> db.<Collection>.updateMany(findingObj, {$set: { value: 240 } });
        It will update all the available finded objects.


    13. Delete Operation in MongoDB

    Property:
        ->  We cannot delete/Update _id
        -> db.expenses.updateOne({ title: "Grocery" }, {$unset: { value: "" }});
            It will delete the value property from that document

    Document:
        -> db.expenses.deleteOne({ title: "Grocery" });
            It will find the document and delete it

    Collection:
        -> db.<collectionName>.drop()
            It will delete the collection

    Database:
        -> for deleting we should be in the database.
        -> db.dropDatabase()
            It will delete all the collections, document inside the DB.

    14. DataTypes in MongoDB
   
        # MongoDB Data Types Table

| **Data Type**       | **Description**                                         | **Example**                     |
|----------------------|---------------------------------------------------------|---------------------------------------|
| **ObjectId**         | A unique identifier for documents                      | `ObjectId()`                          |
| **Number (Int32)**     | Stores integer values                                  | `NumberInt(42)`                       |
| **Number (Int64) (Long)**    | Stores 64-bit integer values                           | `NumberLong("9223372036854775807")`   |
| **Double**           | Stores floating-point numbers                          | `NumberDouble(3.14)`                  |
| **Decimal128**       | Stores high-precision decimal values                   | `NumberDecimal("123.4567890123456789")` |
| **String**           | Stores text data                                       | `"Hello, World!"`                     |
| **Boolean**          | Stores true or false values                            | `true`, `false`                       |
| **Date**             | Stores date and time values                            | `new Date()`                          |
| **Array**            | Stores an array of values                              | `[1, 2, 3, "text"]`                   |
| **Embedded Document (Object)**| Stores nested documents                                | `{ "key": "value" }`                  |
| **Null**             | Represents a null value                                | `null`                                |
| **Binary Data**      | Stores binary data, such as images or files            | `BinData(0, "data")`                  |
| **Regular Expression** | Stores regex patterns                                | `/pattern/i`                          |
| **Code**       | Stores JavaScript code                                 | `Code("function() { return 42; }")`   |
| **Code (Scoped)** | Stores JavaScript code with a scope                 | `Code("function() { return x; }", {x: 42})` |
| **Min Key**          | Represents the smallest possible value in BSON         | `MinKey()`                            |
| **Max Key**          | Represents the largest possible value in BSON          | `MaxKey()`                            |
| **Timestamp**        | Stores timestamp values                                | `Timestamp()`                         |



15.MongoDB ObjectId DataType

ObjectId DataTye

    -> ObjectId is 12 bytes = 24-character hex string.
    -> Structure: 4-byte timestamp, 5-byte machine info, 3-byte counter.
    -> Ensures global uniqueness.
    -> You can override _id, but if not provided, MongoDB generates it automatically.


16. Understanding Number DataTypes in MongoDB

MongoDB Number Data Types

    Int32 (Standard Number)

        -> Used for regular integers.
        -> Suitable for most everyday use cases.
        -> Range is from -2,147,483,648 to 2,147,483,647.

    Int64 â€“ NumberLong()

        -> Used for very large integers that exceed the Int32 range.
        -> Required when numbers go beyond JavaScript's safe integer limit.

    Decimal128 â€“ NumberDecimal()

        -> Used for high-precision decimal values.
        -> Ideal for financial or scientific data where rounding errors must be avoided.


  17.MongoDB DataTypes in Practice

Other Data Types

String
    -> Most commonly used data type.
    -> Stores text values like "name": "Sahil".

Boolean
    -> Stores true or false.
    -> Useful for flags or conditions like "isActive": true.

Date
    -> Stores date and time in ISODate format.
    -> Example: ISODate("2025-05-26T00:00:00Z").

Array
    -> Stores a list of values.
    -> Example: "tags": ["nodejs", "mongodb"].

Object (Embedded Document)
    -> Stores nested documents inside a field.
    -> Example: "address": { "city": "Mumbai", "zip": 400001 }.

null
    -> Stores a null value, like "middleName": null.

Regular Expression (regex)
    -> Stores a regular expression pattern for matching strings.
    -> Example: { name: { $regex: /^S/ } }.

MinKey
    -> A special value that is always less than any other value in MongoDB.
    -> Used mainly for internal operations like range queries.

MaxKey
    -> Opposite of MinKey. Always greater than any other value.
    -> Also used in range operations and comparisons.

   18. BSON Types in MongoDB
# BSON Types

| **Type**             | **Alias**         | **Numeric Code** |
|-----------------------|-------------------|------------------|
| Double               | `double`         | 1                |
| String               | `string`         | 2                |
| Object               | `object`         | 3                |
| Array                | `array`          | 4                |
| Binary Data          | `binData`        | 5                |
| Undefined (deprecated) | `undefined`     | 6                |
| ObjectId             | `objectId`       | 7                |
| Boolean              | `bool`           | 8                |
| Date                 | `date`           | 9                |
| Null                 | `null`           | 10               |
| Regular Expression   | `regex`          | 11               |
| JavaScript           | `javascript`     | 13               |
| Symbol (deprecated)  | `symbol`         | 14               |
| JavaScript (with scope) | `javascriptWithScope` | 15      |
| 32-bit Integer       | `int`            | 16               |
| Timestamp            | `timestamp`      | 17               |
| 64-bit Integer       | `long`           | 18               |
| Decimal128           | `decimal`        | 19               |
| Min Key              | `minKey`         | -1               |
| Max Key              | `maxKey`         | 127              |


19. Where is the Data Stored in MongoDB?

    MongoDB Data Storage Summary

    Default data folder on Windows: C:\data\db
    (Data is stored here in binary format.)

    Custom data path:
        -> You can specify your own storage location when starting MongoDB with:
            mongod --dbpath <your_custom_path>

    Important:
        -> The specified folder must exist before running the command.


20. Configuring MongoDB Server with mongod.cfg File

    MongoDB Config File 

    -> Itâ€™s a text file where you tell MongoDB how to run.

    -> You can set things like:
        -> Where to save your data (dbPath).
        -> Where to save logs.
        -> What network address and port to use.

    Example to set data folder:
        storage:
        dbPath: C:\my_mongo_data

    -> To start MongoDB using this file, run:
        mongod --config path\to\mongod.config

21.Accessing Our MongoDB Server Over the Internet

 mongod.conf

# for documentation of all options, see:
#   http://docs.mongodb.org/manual/reference/configuration-options/

# Where and how to store data.
storage:
  dbPath: C:\Users\anura\OneDrive\Desktop\myDB

# where to write logging data.
# systemLog:
#   destination: file
#   logAppend: true
#   path:  C:\Program Files\MongoDB\Server\8.0\log\mongod.log

# network interfaces
net:
  port: 27017
  bindIp: 0.0.0.0,[::]
  ipv6: true


#processManagement:

#security:

#operationProfiling:

#replication:

#sharding:

## Enterprise-Only Options:

#auditLog:


22.Running MongoShell Scripts in JS Files

Run JavaScript files using the Mongo shell:
        mongosh your_script.js

    -> Inside the JS file, write only valid JavaScript code using MongoDB API methods.

    -> Use db.getCollection("name") to access collections, especially if the collection name has special characters or spaces.


  23.What is MongoDB Playground?

  MongoDB Playground is an interactive environment (mainly in VS Code) that lets you:
    -> Write and run MongoDB queries using JavaScript-like syntax.
    -> Test database scripts like insert, find, update, etc.
    -> Connect to real databases (local or remote).
    -> Preview results inline in the editor.


    


  24. MongoDB in Node.js

      MongoDB provides drivers for every popular backend language to work with it.
-> We also have Driver for NodeJS
-> Installation: npm i mongodb

-> Import and Connect
    import { MongoClient } from "mongodb";
    const client = new MongoClient("mongodb://127.0.0.1:27017/");
    await client.connect(); // Connect to MongoDB server

-> Database Access
    const db = client.db();               // Default 'test' DB
    const db = client.db("DataBaseName"); // Use a specific DB

-> View Collections
    console.log(await db.listCollections().toArray());
    // Lists all collections in the selected DB

-> Access Documents in a Collection
    const collection = db.collection("fruits");
    console.log(await collection.find().toArray());
    // Fetches all documents in the 'fruits' collection

-> List All Databases
    const admin = client.db().admin();
    console.log(await admin.listDatabases());
    // Lists all databases on the server

25.MongoDB CRUD Operation in Node.js


 Setup
    const db = client.db("DataBaseName");
    const collection = db.collection("users");

-> Read
    const users = await collection.find().toArray();

-> Create
    await collection.insertOne({ name: "XYZ", email: "x@g.com", age: 34 });

-> Update
    await collection.updateOne(
    { _id: new ObjectId("...") },
    { $set: { age: 35 } }
    );

-> Delete
    await collection.deleteOne({ _id: new ObjectId("...") });
    await collection.drop();         // Drop collection
    await db.dropDatabase();         // Drop DB
    

27.Understanding Cursors in MongoDB.

What is a Cursor?
    -> A Cursor is a JS object returned by .find().
    -> It stores query metadata and doesn't hit DB until a method like .toArray() or .next() is called.

Cursor as an Async Iterator
    -> const cursor = collection.find(); // returns a cursor
    -> cursor[Symbol.asyncIterator];     // true â‡’ it's iterable

    -> You can use:
        for await (const doc of cursor) {
        console.log(doc);
        }

Cursor Methods(few)

    -> await cursor.next();     // Returns next document or null
    -> await cursor.hasNext();  // Returns true/false

    
28. Cursor Methods in MongoDB

Cursor Chaining
-> Methods like .limit(), .skip(), .sort() return the cursor itself (not a promise).
-> You can chain them before executing with .toArray() or iterating.
-> Common Methods
    collection.find()
    .limit(5)                 // Limit result to 5 docs
    .skip(2)                  // Skip first 2 docs
    .sort({ name: 1, age: -1 }) // Sort by name â†‘, then age â†“
-> No DB call is made until you use .toArray(), .next(), or a loop.


The Setup (const cursor = find()):
You create a cursor object. This is just a set of instructions. No request has been sent.
The cursor object has an empty internal cache (currentBatch: []), no cursorId, and methods like next().

The Trigger: The First Request
The First Request (First next(), Start of for-await, or toArray()):

The moment you call a method that needs data (await cursor.next(), start a for await (const doc of cursor) loop, or await cursor.toArray()), the process begins.

The cursor sends the initial query to the server for the first time.
The server executes the query and sends back the first batch of documents (e.g., 100 docs) along with a unique Cursor ID.
The cursor object stores this first batch in its internal currentBatch array and saves the cursorId.

How Each Method Consumes the Data
A. Using await cursor.next():

First Call to await cursor.next():

The method pops the first document off the currentBatch array and returns it to you.

The internal state now holds 99 documents.

Calls #2 to #100 to await cursor.next():

The method has documents in its local currentBatch. It simply pops the next one off and returns it immediately. This requires NO trip to the server.

Call #101 to await cursor.next():

The method finds the currentBatch empty.

It uses the stored cursorId to send a getMore command to the server.

The server sends the next batch.

The cursor stores this new batch and returns the first document from it.

This process repeats until the server sends an empty batch.

B. Using for await (const doc of cursor):

The Loop is a Wrapper for next():

Starting the loop implicitly makes the first call to await cursor.next(), triggering the initial query and populating the first batch (Step 2 above).

Each iteration of the loop automatically calls await cursor.next() for you.

The variable doc is set to the result of that next() call.

Iterations #2 to #100:

Each loop iteration pops a document from the local currentBatch. No server trips.

Iteration #101:

The loop's automatic call to next() triggers a getMore command to fetch the next batch.

The loop continues with the new batch.

The loop ends when next() has no more data to return.

C. Using await cursor.toArray():

The Method Takes Over:

The method triggers the initial query (Step 2 above).

It does not return. Instead, it enters a hidden, aggressive loop.

The Internal Loop:

It continuously pops all documents from the currentBatch and pushes them into a new, growing array.

When the currentBatch is empty, it automatically sends a getMore command using the cursorId to fetch the next batch.

It immediately empties that new batch into the array.

The Return:

It repeats this processâ€”emptying batches, sending getMore commandsâ€”until the server has no more data.
Only then does the method return the complete, massive array containing every single document.

The Finale
Completion:

For all methods, the process ends when the server sends back an empty batch, signaling there is no more data. The cursor is then closed.


29. Batch Size in MongoDB

    What is Batch Size?
-> MongoDB returns documents in batches, not all at once.
-> Batch size controls how many docs are returned per network request.

Set Batch Size
-> const cursor = collection.find().batchSize(10);
-> This sets the batch size to 10 documents.
-> MongoDB will send results in chunks of 10 until all are returned.

Notes > Improves memory usage and performance for large datasets.


30.Projection in MongoDB

What is Projection?
-> Projection controls which fields are returned in the query result.

Include Fields
-> // Include only "name" and "email"
-> const users = await collection.find({}, { projection: { name: 1, email: 1 } }).toArray();

Exclude Fields
-> // Exclude "age"
-> const users = await collection.find({}, { projection: { age: 0 } }).toArray();

Note
-> 1 = include, 0 = exclude
-> You can't mix include and exclude (except for _id).


31.Limits of MongoDB
# MongoDB Limits and Thresholds

## 1. Document Size Limits
- **Maximum Document Size**: 16MB (BSON format)
  - Affects: Single document storage, embedded arrays/objects
  - Exception: GridFS for larger files

- **Maximum Array Elements**: ~4,000,000 (practical limit)
- **Maximum Nesting Depth**: 100 levels

## 2. BSON Data Types
- **String**: 16MB maximum
- **Binary Data**: 16MB (use GridFS for larger)
- **Number Precision**: 
  - 64-bit for integers (Long)
  - 64-bit IEEE 754 for doubles

## 3. Indexing Limits
| Limit Type                     | Value               |
|--------------------------------|---------------------|
| Indexes per Collection         | 64                  |
| Index Key Length               | 1024 bytes          |
| Compound Index Fields          | 32 fields           |
| Text Index Fields per Document | 1                   |
| Sharded Cluster Index Key Size | 512 bytes           |

## 4. Sharding Limits
- **Shard Key**: 
  - Immutable after creation
  - Maximum size: 512 bytes
- **Maximum Shards**: 1024
- **Chunk Size**: 1MB-1024MB (default 64MB)

## 5. Replication Limits
- **Replica Set Members**: 
  - Maximum 50 members
  - Maximum 7 voting members
- **Oplog Size**: 
  - Minimum 990MB (default for 64-bit systems: 5% disk space)

## 6. Query Limitations
| Operation                  | Limit                |
|----------------------------|----------------------|
| Result Set Size            | 32MB per query       |
| Sort Memory                | 32MB (without index) |
| Aggregation Pipeline Stages| 100 stages           |
| Aggregation Memory         | 100MB per stage      |

## 7. Connection Limits
| Deployment Type       | Default Connection Limit |
|-----------------------|---------------------------|
| MongoDB Atlas         | 500 connections/server    |
| Self-Managed Community| 16,000 connections        |
| Self-Managed Enterprise| 125,000 connections       |

## 8. Write Operations
- **Atomicity**: Single document level
- **Write Throughput**: ~100,000 ops/sec per shard
- **Bulk Write Batch Size**: 100,000 operations

## 9. Database/Collection Limits
| Entity           | Limit                         |
|------------------|-------------------------------|
| Databases        | 40 (Atlas limit per project)  |
| Collections      | 1000 per database (namespace) |
| Namespace Length | 123 bytes (db.collection)     |

## 10. Security Limits
- **Authentication**:
  - 16MB user name limit (LDAP)
  - 250 roles per user
- **X.509 Certificates**:
  - 25 attributes per certificate

## 11. MongoDB Atlas Specific
- **Document Storage**: 512MB per document
- **Free Tier**: 
  - 512MB storage
  - Shared RAM
- **Backups**: 2 days retention (free tier)

## Important Notes
1. Most limits are configurable (except fundamental BSON/document limits)
2. Workarounds exist for many limits (e.g., GridFS for large files)
3. Monitor with `db.serverStatus()` and `currentOp`



33.Using $in Operator for Bulk Operation in MongoDB

The $in operator in MongoDB checks if a fieldâ€™s value exists in a specified array.
-> Syntax:
    { field: { $in: [value1, value2, ...] } }

-> Example:
    db.users.find({ age: { $in: [18, 25, 30] } });
    Matches users whose age is 18, 25, or 30.

-> Use case: Efficiently fetch multiple values in one query.

34. Why ObjectId is Not a String?

 Why ObjectId is not a String in MongoDB?

-> ObjectId is a special type in MongoDB that takes only 12 bytes, while a string version would take 24 bytes.
-> It is more efficient because it uses half the space of a string.
-> In hex, 2 characters = 1 byte.
-> An ObjectId is made up of:
    -> Timestamp
    -> Machine ID & Process ID
    -> Counter
-> MongoDB uses the binary (12-byte) form, not the full string, when inserting or querying.

35. Understanding Application Architecture

Application Architecture (Tiers)

    Tier-1 (Single-Tier)
        -> Runs on one machine, no network.
        -> Eg: Calculator, Notepad

    Tier-2 (Client-Server)
        -> Client: UI
        -> Server: Logic + Database
        -> Eg: MySQL Client, Online banking software

    Tier-3
        -> Frontend: UI
        -> Backend: Logic
        -> Database: Storage
        -> Eg: E-commerce sites, Social media apps

    Tier-N (Multi-Tier)
        -> 3-Tier + Services like CDN, AWS, Auth, Cache
        -> Eg: Netflix, YouTube, Large SaaS apps

  36. Ordered Inserts in MongoDB
Ordered Inserts

    -> Documents are inserted in order.
    -> If any insert fails, remaining inserts are stopped, and an error is thrown.
    -> To continue inserting remaining valid documents, use:
        { ordered: false }

37.What is Upsert in MongoDB?

Upsert

    -> If the document exists â†’ it gets updated.
    -> If the document doesnâ€™t exist â†’ it gets inserted.
    -> Use the upsert: true flag.
    -> db.collection.updateOne(filter, update, { upsert: true });

   38. Running Commands in MongoDB

# MongoDB Commands Categorized

## 1. **Database Commands**

### ðŸ“Œ General Database Operations

- **List Databases**
  ```js
  db.runCommand({ listDatabases: 1 });
  ```
- **List Available Commands**
  ```js
  db.runCommand({ listCommands: 1 });
  ```
- **Get Database Stats**
  ```js
  db.runCommand({ dbStats: 1 });
  ```
- **Drop Database**
  ```js
  db.runCommand({ dropDatabase: 1 });
  ```

---

## 2. **Collection Commands**

### ðŸ“Œ Collection Management

- **Create Collection**
  ```js
  db.runCommand({ create: "myCollection" });
  ```
- **Drop Collection**
  ```js
  db.runCommand({ drop: "myCollection" });
  ```
- **List Collections**
  ```js
  db.runCommand({ listCollections: 1 });
  ```
- **Rename Collection**
  ```js
  db.runCommand({ renameCollection: "oldName", to: "newName" });
  ```
- **Validate Collection**
  ```js
  db.runCommand({ validate: "myCollection" });
  ```

---

## 3. **CRUD (Create, Read, Update, Delete) Commands**

### ðŸ“Œ Insert Documents

- **Insert One or Multiple Documents**
  ```js
  db.runCommand({
    insert: "myCollection",
    documents: [
      { name: "Alice", age: 30 },
      { name: "Bob", age: 22 },
    ],
  });
  ```

### ðŸ“Œ Read Documents

- **Find Documents**
  ```js
  db.runCommand({
    find: "myCollection",
    filter: { age: { $gt: 18 } },
    projection: { _id: 0, name: 1, age: 1 },
    limit: 5,
  });
  ```

### ðŸ“Œ Update Documents

- **Update One or Multiple Documents**
  ```js
  db.runCommand({
    update: "myCollection",
    updates: [{ q: { name: "Alice" }, u: { $set: { age: 35 } }, upsert: true }],
  });
  ```

### ðŸ“Œ Delete Documents

- **Delete One or Multiple Documents**
  ```js
  db.runCommand({
    delete: "myCollection",
    deletes: [{ q: { age: { $lt: 25 } }, limit: 0 }],
  });
  ```

---

## 4. **Index Commands**

### ðŸ“Œ Index Management

- **Create Index**
  ```js
  db.runCommand({
    createIndexes: "myCollection",
    indexes: [{ key: { name: 1 }, name: "name_index" }],
  });
  ```
- **List Indexes**
  ```js
  db.runCommand({ listIndexes: "myCollection" });
  ```
- **Drop Index**
  ```js
  db.runCommand({ dropIndexes: "myCollection", index: "name_index" });
  ```

---

## 5. **Replication Commands**

### ðŸ“Œ Replica Set Status & Configuration

- **Get Replica Set Status**
  ```js
  db.runCommand({ replSetGetStatus: 1 });
  ```
- **Get Replica Set Configuration**
  ```js
  db.runCommand({ replSetGetConfig: 1 });
  ```
- **Step Down Primary Node**
  ```js
  db.runCommand({ replSetStepDown: 60 });
  ```

---

## 6. **Sharding Commands**

### ðŸ“Œ Shard Management

- **Enable Sharding for a Database**
  ```js
  db.runCommand({ enableSharding: "myDatabase" });
  ```
- **Shard a Collection**
  ```js
  db.runCommand({
    shardCollection: "myDatabase.myCollection",
    key: { _id: 1 },
  });
  ```
- **Get Shard Status**
  ```js
  db.runCommand({ getShardMap: 1 });
  ```

---

## 7. **Server & Performance Monitoring Commands**

### ðŸ“Œ Server Status & Diagnostics

- **Get Server Status**
  ```js
  db.runCommand({ serverStatus: 1 });
  ```
- **Get Host Information**
  ```js
  db.runCommand({ hostInfo: 1 });
  ```
- **Get Running Operations**
  ```js
  db.runCommand({ currentOp: 1 });
  ```
- **Kill Running Operation**
  ```js
  db.runCommand({ killOp: 1, op: <opid> });
  ```
- **Rotate Logs**
  ```js
  db.runCommand({ logRotate: 1 });
  ```

---

## 8. **Security & Access Control Commands**

### ðŸ“Œ User & Role Management

- **Create User**
  ```js
  db.runCommand({
    createUser: "admin",
    pwd: "securepassword",
    roles: ["readWrite", "dbAdmin"],
  });
  ```
- **Drop User**
  ```js
  db.runCommand({ dropUser: "admin" });
  ```
- **List Users**
  ```js
  db.runCommand({ usersInfo: 1 });
  ```
- **Grant a Role to a User**
  ```js
  db.runCommand({ grantRolesToUser: "admin", roles: ["read"] });
  ```

---

## 9. **Logging & Debugging Commands**

### ðŸ“Œ Logs & Configuration

- **Get Log Data**
  ```js
  db.runCommand({ getLog: "global" });
  ```
- **List Available Logs**
  ```js
  db.runCommand({ getLog: "startupWarnings" });
  ```
- **Get Server Parameters**
  ```js
  db.runCommand({ getParameter: "*" });
  ```

---

## ðŸŽ¯ **Final Notes**

- The `db.runCommand()` method in **Mongo shell** and `db.command()` in **Node.js driver** work the same way.
- Some commands are **administrative** and require proper permissions.
- **For CRUD operations**, the standard `insertOne()`, `find()`, `updateOne()`, `deleteOne()` methods are more convenient.

This document categorizes all the essential MongoDB commands for managing databases, collections, and server operations.


39.Operators in MongoDB

# MongoDB Query and Projection Operators

This document covers the most commonly used **Query and Projection Operators** in MongoDB with **Node.js examples**.

---

## ðŸ“Œ 1. Query Operators

Query operators are used to filter documents based on specific conditions.

### ðŸ”¹ `$eq` (Equal)

Finds documents where a field is equal to a specified value.

```js
const result = await db
  .collection("users")
  .find({ age: { $eq: 25 } })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$ne` (Not Equal)

Finds documents where a field is **not** equal to a specified value.

```js
const result = await db
  .collection("users")
  .find({ status: { $ne: "inactive" } })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$gt`, `$gte`, `$lt`, `$lte` (Greater Than, Less Than)

```js
const result = await db
  .collection("users")
  .find({ age: { $gt: 18 } })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$in`, `$nin` (Match any of the specified values / Not in)

```js
const result = await db
  .collection("users")
  .find({ country: { $in: ["India", "USA"] } })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$exists` (Check if a field exists)

```js
const result = await db
  .collection("users")
  .find({ phone: { $exists: true } })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$regex` (Pattern Matching)

```js
const result = await db
  .collection("users")
  .find({ name: { $regex: /^A/i } })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$or`, `$and`, `$not`, `$nor` (Logical Operators)

```js
const result = await db
  .collection("users")
  .find({
    $or: [{ age: { $gt: 30 } }, { status: "active" }],
  })
  .toArray();
console.log(result);
```

---

## ðŸ“Œ 2. Projection Operators

Projection operators control which fields are returned in the result.

### ðŸ”¹ Inclusion (`1`) and Exclusion (`0`)

```js
const result = await db
  .collection("users")
  .find({}, { projection: { name: 1, age: 1, _id: 0 } })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$elemMatch` (Match elements in an array)

```js
const result = await db
  .collection("users")
  .find({
    hobbies: { $elemMatch: { type: "sports" } },
  })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$slice` (Limit array fields in results)

```js
const result = await db
  .collection("users")
  .find({}, { projection: { posts: { $slice: 2 } } })
  .toArray();
console.log(result);
```

---

## ðŸ“Œ 3. Array Query Operators

### ðŸ”¹ `$all` (Match all values in an array)

```js
const result = await db
  .collection("users")
  .find({ skills: { $all: ["MongoDB", "Node.js"] } })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$size` (Find arrays with a specific number of elements)

```js
const result = await db
  .collection("users")
  .find({ skills: { $size: 3 } })
  .toArray();
console.log(result);
```

---

## ðŸ“Œ 4. Evaluation Operators

### ðŸ”¹ `$expr` (Compare two fields)

```js
const result = await db
  .collection("users")
  .find({
    $expr: { $gt: ["$credits", "$debits"] },
  })
  .toArray();
console.log(result);
```

### ðŸ”¹ `$mod` (Modulo operation)

```js
const result = await db
  .collection("users")
  .find({ age: { $mod: [2, 0] } })
  .toArray();
console.log(result);
```


# MongoDB Update Operators

This document categorizes and explains the most commonly used **Update Operators** in MongoDB with **Node.js examples**.

---

## ðŸ“Œ 1. Field Update Operators

### ðŸ”¹ `$set` (Update or Add a Field)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $set: { age: 30 } }
);
console.log(result);
```

### ðŸ”¹ `$unset` (Remove a Field)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $unset: { age: "" } }
);
console.log(result);
```

### ðŸ”¹ `$rename` (Rename a Field)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $rename: { "oldField": "newField" } }
);
console.log(result);
```

---

## ðŸ“Œ 2. Arithmetic Operators

### ðŸ”¹ `$inc` (Increment a Numeric Field)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $inc: { score: 5 } }
);
console.log(result);
```

### ðŸ”¹ `$mul` (Multiply a Numeric Field)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $mul: { salary: 1.1 } }
);
console.log(result);
```

---

## ðŸ“Œ 3. Array Update Operators

### ðŸ”¹ `$push` (Add an Element to an Array)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $push: { skills: "MongoDB" } }
);
console.log(result);
```

### ðŸ”¹ `$pop` (Remove First or Last Element from an Array)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $pop: { skills: -1 } } // -1 removes first, 1 removes last
);
console.log(result);
```

### ðŸ”¹ `$pull` (Remove Specific Elements from an Array)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $pull: { skills: "Java" } }
);
console.log(result);
```

### ðŸ”¹ `$addToSet` (Add an Element Only If It Does Not Exist)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $addToSet: { skills: "JavaScript" } }
);
console.log(result);
```

---

## ðŸ“Œ 4. Upsert Operations

### ðŸ”¹ `upsert: true` (Insert if Not Found)
```js
const result = await db.collection("users").updateOne(
  { name: "Jane" },
  { $set: { age: 25 } },
  { upsert: true }
);
console.log(result);
```

---

## ðŸ“Œ 5. Date Operators

### ðŸ”¹ `$currentDate` (Set Field to Current Date)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $currentDate: { lastLogin: true } }
);
console.log(result);
```

---

## ðŸ“Œ 6. Bitwise Operators

### ðŸ”¹ `$bit` (Bitwise Operations on Integer Fields)
```js
const result = await db.collection("users").updateOne(
  { name: "John" },
  { $bit: { permissions: { or: 5 } } }
);
console.log(result);
```

40.What is Schema?

Schema

    -> A schema defines the structure of data in a database.
    -> It sets field names, data types, and rules (like required fields).
    -> MongoDB is schema-less, but using schemas (e.g., with Mongoose) ensures data consistency and validation.
    -> Useful for catching errors, maintaining uniformity, and writing reliable queries.


42. Understanding jsonSchema Validation
Defines strict structure, data types, and rules for documents.
-> Supports nested validation.
-> additionalProperties: false blocks extra unwanted fields.

-> Example with Nested Fields:

db.createCollection("users", {
validator: {
    $jsonSchema: {
    bsonType: "object",
    required: ["name", "age", "address"],
    additionalProperties: false,
    properties: {
        name: { bsonType: "string" },
        age: { bsonType: "int", minimum: 18 },
        address: {
        bsonType: "object",
        required: ["city", "zip"],
        additionalProperties: false,
        properties: {
            city: { bsonType: "string" },
            zip: { bsonType: "int" }
        }
        }
    }
    }
}
});


43.Validation Action VS Validation Level
These two control how MongoDB handles documents that fail validation.

1) Validation Action
-> What happens when a document fails validation?
    -> error (default): Reject the insert or update.
    -> warn: Allow the operation but log a warning.
-> validationAction: "error" // or "warn"

2) Validation Level
-> Which documents are checked during validation?
    -> strict (default): Validate all inserts and updates.
    -> moderate: Validate only documents that already have the validated fields.
    -> off (MongoDB 7.0+): Disable validation.
-> validationLevel: "strict" // or "moderate"

44.Finding Invalid Documents in a Collection
For finding invalid document in collection

db.collection("users").find({
$nor: [{ $jsonSchema: { ...your schema... } }]
});

44. What Are Transactions in Database?
Transactions in Database

-> In MongoDB, transactions are a feature that allows you to group multiple read and write operations into a single atomic operation â€” meaning either all operations succeed, or none of them are applied. This is similar to transactions in relational databases (like MySQL or PostgreSQL).

-> Why Use Transactions in MongoDB?

MongoDB is a NoSQL database and was originally designed with single-document atomicity in mind. However, in some cases, you need multi-document or multi-collection atomic operations, such as:
    -> Transferring money between accounts.
    -> Updating multiple collections consistently.
    -> Undoing partial updates if something fails.
    -> For these use cases, MongoDB supports multi-document transactions starting from version 4.0 for replica sets and 4.2+ for sharded clusters.

-> Key Properties of Transactions:
    -> Atomicity: All changes in a transaction are either fully applied or not applied at all.
    -> Consistency: The database moves from one valid state to another.
    -> Isolation: Operations in a transaction are invisible to others until committed.
    -> Durability: Once committed, changes are permanent even if there's a crash.


 45.Implementing Transaction in Code

 Steps to enable transaction in MongoDB

    1. Edit the Config File (mongod.conf)

        -> Add the following under the replication section:
            replication:
                replSetName: rs0

    2. Restart the MongoDB service if installed as a service on Windows

    3. Initiate the Replica Set
        -> In the shell, run: rs.initiate()

    4. Verify Status: rs.status()

    5. Change the connection String: mongodb://localhost:27017/?replicaSet=rs0


   46.ACID Properties of a Transaction

   ACID = Atomicity, Consistency, Isolation, Durability

-> Atomicity:
All steps in a transaction happen, or none happen.
"All or nothing."

-> Consistency:
The database follows rules before and after the transaction.
"Data stays valid."

-> Isolation:
Transactions donâ€™t interfere with each other.
"No mix-ups when multiple users act at once."

-> Durability:
Once a transaction is saved, it stays saved â€” even after a crash.
"It's permanent."

Sharding:
Sharding distributes data across multiple servers, allowing you to manage and query very large datasets more efficiently. Each shard holds a subset of the overall data, which helps improve performance by balancing the load.

Replication:
Replication involves creating multiple copies of the same data across different servers. This ensures high availability and fault tolerance. If one server is busy or fails, another server with a replica can handle the request, which reduces latency and ensures continuity. right?


47.Relational vs. Non-Relational Databases: Key Differences

Relational Vs Non-Relational DBs

1. Structure
    -> Relational:
        Stores data in tables (like Excel sheets â€“ rows and columns).
    -> Non-Relational:
        Stores data in flexible formats like JSON, key-value pairs, or graphs.

2. Schema
    -> Relational:
        Fixed structure â€“ you must define the format before adding data.
    -> Non-Relational:
        No fixed structure â€“ you can store different types of data freely.

3. Scalability
    -> Relational:
        Grows by getting a bigger machine (vertical scaling).
    -> Non-Relational:
        Grows by adding more machines (horizontal scaling), easier for big systems.

4. ACID
    -> Relational:
        Follows strict rules to keep data accurate and safe (ACID).
    -> Non-Relational:
        May skip some rules for better speed and flexibility.

5. Query Language
    -> Relational:
        Uses SQL â€“ a standard language to ask and manage data.
    -> Non-Relational:
        Uses different methods depending on the type (not always SQL).

6. Examples
    -> Relational:
        MySQL, PostgreSQL, Oracle
    -> Non-Relational:
        MongoDB (document), Redis (key-value), Cassandra (wide-column), Neo4j (graph).

   49.Embedded vs. Referenced Documents: Choosing the Right Data Model
Embedded Documents
    -> Meaning: Related data is stored inside the same document.
    -> Example:
        {
        "name": "John",
        "address": { "city": "Mumbai", "zip": "400001" }
        }
    -> Good for: Data used together
    -> Pros: Fast reads
    -> Cons: Can get large, harder to update

Referenced Documents
    -> Meaning: Related data is stored in a separate document and linked by ID.
    -> Example:
        {
        "name": "John",
        "address_id": "abc123"
        }
    -> Good for: Shared or large data
    -> Pros: Cleaner, flexible
    -> Cons: Requires extra query to fetch related data

# Embedded vs. Referenced Documents

## Introduction
In NoSQL databases, particularly in document-based databases like MongoDB, data relationships can be handled using **embedded** or **referenced** documents. The choice between these approaches affects performance, scalability, and ease of querying.

## 1. Embedded Documents
Embedded documents store related data within the same document.

### Pros:
- **Faster Reads**: Data retrieval is quicker since related data is stored together.
- **Fewer Joins**: No need for complex queries or additional lookups.
- **Atomic Updates**: Easier to update related data in a single operation.

### Cons:
- **Data Duplication**: Can lead to redundancy if the same sub-document is used in multiple documents.
- **Limited Scalability**: Large nested documents can impact performance and exceed document size limits.

### Example:
```json
{
  "_id": 1,
  "name": "John Doe",
  "orders": [
    { "order_id": 101, "amount": 50 },
    { "order_id": 102, "amount": 75 }
  ]
}
```

## 2. Referenced Documents
Referenced documents store relationships using document references (IDs).

### Pros:
- **Better Scalability**: Useful for large datasets where embedding would exceed size constraints.
- **Efficient Updates**: Changes to referenced documents donâ€™t require updating multiple documents.
- **Normalization**: Reduces redundancy and improves maintainability.

### Cons:
- **Slower Reads**: Requires additional lookups to retrieve related data.
- **Increased Query Complexity**: Queries involve joins or multiple fetch operations.

### Example:
```json
{
  "_id": 1,
  "name": "John Doe",
  "orders": [101, 102]
}

{
  "_id": 101,
  "order_id": 101,
  "amount": 50
}

{
  "_id": 102,
  "order_id": 102,
  "amount": 75
}
```

## 3. When to Use Each Approach
| Use Case | Embedded Documents | Referenced Documents |
|----------|--------------------|---------------------|
| Data is frequently read together | âœ… | âŒ |
| Data relationships are complex and scalable | âŒ | âœ… |
| Updates are frequent across multiple documents | âŒ | âœ… |
| Document size constraints are not a concern | âœ… | âŒ |

## Conclusion
Choosing between embedded and referenced documents depends on the applicationâ€™s needs. Use **embedded documents** when data is closely related and frequently accessed together. Use **referenced documents** when scalability, normalization, and flexibility are priorities.

50.Understanding One-to-One, One-to-Many, and Many-to-Many Relationships

1. One-to-One
    Meaning: One document is related to only one other document.
    Example: A User has one Profile.

2. One-to-Many
    Meaning: One document relates to many documents.
    Example: A Blog Post has many Comments.

3. Many-to-Many
    Meaning: Many documents relate to many others.
    Example: Students enrolled in many Courses, and Courses have many Students.


51. Backup & Restore Using mongodump and mongorestore

mongodump (Backup)
    -> Creates a backup of MongoDB data in BSON format.
    -> Can dump entire DB, specific DB, or collections.
    -> Supports options like compression (--gzip), authentication, and dumping to archive files.
    -> Example:
        mongodump --db mydatabase --out /backup/mongo/

mongorestore (Restore)
    -> Restores data from BSON backups created by mongodump.
    -> Can restore entire dump, specific DB, or collections.
    -> Supports options like dropping existing data before restore (--drop), authentication, and reading from archives or compressed files.
    -> Example:
        mongorestore --db mydatabase /backup/mongo/mydatabase/

52.Using mongoexport and mongoimport to Export and Import JSON or CSV Data

mongoexport (Export Data)
    -> Exports data from MongoDB to JSON or CSV files.
    -> Useful for sharing or backing up in readable formats.
    -> Common Options:
        --db, --collection, --out, --type, --fields, --query, --jsonArray
    -> Example:
        mongoexport --db mydatabase --collection users --out users.json

mongoimport (Import Data)
    -> Imports data into MongoDB from JSON or CSV files.
    -> Used to restore, migrate, or populate data.
    -> Common Options:
        --db, --collection, --file, --type, --fields, --jsonArray, --drop
    -> Example:
        mongoimport --db mydatabase --collection users --file users.json

  53. mongodump VS mongoexport: When to Use What?

  54. mongodump / mongorestore (Binary Backup & Restore)
    Use when:
        -> You need a full backup or restore of a database/collection
        -> You want to preserve MongoDB-specific types (e.g. ObjectId, Date).
        -> Youâ€™re migrating between MongoDB servers.
        -> You need fast, efficient backup (BSON format).

    Avoid when:
        -> You need human-readable or filtered data.

mongoexport / mongoimport (Structured Data Transfer)
    Use when:
        -> You want to export/import JSON or CSV.
        -> You need to filter or share specific fields or documents.
        -> You're migrating to another database system (e.g. PostgreSQL).

    Avoid when:
        -> You want a complete backup with indexes and metadata.

  55.Securing MongoDB: Authentication and Authorization
  We can change password of a user:

db.changeUserPassword("username", "newPassword")

Roles that can change any user's password:
root - All users (cluster-wide)
userAdminAnyDatabase - All users (cluster-wide)
userAdmin - Users of that DB only
dbOwner - Users of that DB only



We should not create all the users inside the admin database we should create the user in the database in which that user belongs. This is considered as a good practice.
And you don't need to remember all the users you can get all users along with their database info by running this `db.system.users.find()` query inside the admin database.

56.Enabling Auth in MongoDB Replica Set
# Enabling Authentication in MongoDB Replica Set

## 1. **Generating the KeyFile**

To enable authentication in a MongoDB replica set, you need to create a keyFile for internal authentication between the nodes.

### **Step 1: Generate a KeyFile**

Run the following command to generate a secure key file:

```sh
openssl rand -base64 756 > /path/to/mongo-keyfile
```

### **Step 2: Set Correct Permissions (Only for Unix Systems)**

Ensure that the key file has the correct permissions:

```sh
chmod 400 mongo-keyfile
```

## 2. **Configuring MongoDB to Use the KeyFile**

Add the following lines under the `security` section in the MongoDB configuration file (`mongod.conf`):

```yaml
security:
  authorization: enabled
  keyFile: /path/to/mongo-keyfile
```

## 3. **Restart MongoDB Nodes with Authentication**

Once the keyFile is set up, restart all nodes in the replica set:


Now, authentication is enabled for the replica set, and nodes will communicate securely using the keyFile.

57.Exploring MongoDB Atlas

MongoDB Atlas â€“ Key Points
What is it?
    -> Cloud-based, fully managed MongoDB service.
    -> Hosted by MongoDB Inc.
    -> Supports AWS, GCP, and Azure.

Features
    -> No server setup required â€“ fully managed.
    -> Free tier available (M0 cluster)
    -> Built-in security: IP whitelisting, encryption, user roles.
    -> Global clusters for low-latency access.
    -> Auto-scaling & sharding support.
    -> Automated backups with restore options.
    -> Monitoring tools built-in (charts, metrics, alerts).
    -> Easy integrations with Node.js, Python, etc.

How to Use
    -> Sign up at: mongodb.com/cloud/atlas
    -> Create a cluster (select cloud provider and region).
    -> Add your IP address to access list.
    -> Create a database user with username & password.
    -> Connect using:
        -> MongoDB URI in your app
        -> Compass (GUI)
        -> Mongo Shell

58. Managed VS Self-Managed Databases
    # Managed vs. Self-Managed Databases

## Introduction
Choosing between a **managed** and **self-managed** database depends on factors like cost, scalability, maintenance, and control. Below, we compare the pros and cons of both approaches.

---

## **Managed Databases**
Managed databases are cloud-based services where the provider handles infrastructure, maintenance, security, and scaling.

### âœ… **Pros**
1. **Ease of Use**: No need to manage database servers, updates, or backups.
2. **Scalability**: Auto-scaling options make it easier to handle traffic spikes.
3. **Security**: Built-in security measures like encryption, role-based access control, and compliance.
4. **Automated Maintenance**: Handles patching, backups, and disaster recovery.
5. **High Availability**: Redundant systems ensure minimal downtime.
6. **Performance Optimization**: Providers offer monitoring tools for performance tuning.

### âŒ **Cons**
1. **Limited Control**: Cannot fine-tune infrastructure and configurations beyond provider limits.
2. **Cost**: Generally more expensive than self-managed solutions.
3. **Vendor Lock-in**: Moving to a different provider can be difficult and costly.
4. **Customization Restrictions**: Some features may be unavailable or require premium plans.

---

## **Self-Managed Databases**
Self-managed databases require you to install, configure, maintain, and secure your own database servers.

### âœ… **Pros**
1. **Full Control**: Complete access to database configuration, hardware, and optimizations.
2. **Customization**: Ability to tailor settings, performance tuning, and security policies.
3. **Cost Efficiency**: Can be cheaper if you have in-house expertise and infrastructure.
4. **No Vendor Lock-in**: Freedom to migrate and choose the best hosting environment.
5. **Better Performance and Security**: Since the database and server run on the same machine, database operations can be faster. Additionally, there is no need to expose the database to the internet, making it more secure.

### âŒ **Cons**
1. **High Maintenance**: Requires regular patching, backups, and performance tuning.
2. **Security Risks**: Responsibility for securing data, managing access controls, and handling compliance.
3. **Scalability Challenges**: Requires manual effort to add servers and optimize for high traffic.
4. **Downtime Risks**: Failover and disaster recovery must be planned and executed manually.
5. **Operational Complexity**: Requires in-depth knowledge of database management and infrastructure.

---

## **Conclusion**
- **Choose Managed Databases** if you want a hassle-free, scalable, and secure solution with minimal maintenance.
- **Choose Self-Managed Databases** if you need full control, custom configurations, and cost efficiency for large-scale or specialized applications.

The choice ultimately depends on your business needs, technical expertise, and budget.


My further study: 1) sudo means "superuser do" --> it means only access like admin. sudo grants elevated privileges to perform administrative tasks. 2) The name systemctl is a blend of "system" and "control," reflecting its role in controlling and managing systemd services, units, and system states. 3) cat --> it is short form of concatenate that means to join things and although  to display the content. 4) After cat /etc/mongod.conf  shows all contents of mongod.conf. It shows YAML format that means "YAML Ain't (is not) Markup Language" or "Yet Another Markup Language". YAML format defines human readable format. 5) nano --> it means editor that helps us to edit our mongodb configuration file. If we want to edit any file it have to use sudo because sudo means superuser do, only sudo can edit and save the mongodb configuration




                                                              Mastering Database Fundamentals


### SECTION 12

## Introduction to MVC Architecture

    MVC (Model-View-Controller) is a design pattern that helps in organizing code by separating concerns in a Node.js application. It divides the application into three main components:

    ðŸ”¹ Model
        -> Responsible for interacting with the database.
        -> Retrieves, updates, or deletes data.
        -> Represents the business logic.

    ðŸ”¹ View
        -> Handles the UI (User Interface).
        -> Displays data to the user using server-side rendering.
        -> Note: In modern backend development, especially with REST APIs, the View is often handled on the frontend (e.g., React, Angular), so this layer is usually not used in backend code.

    ðŸ”¹ Controller
        -> Manages the application logic.
        -> Handles incoming HTTP requests, interacts with Models, and returns the response (usually in JSON).

    Request-Response Flow in MVC
        -> View (UI) sends a request (e.g., via a form or button click).
        -> The Router receives the request and forwards it to the appropriate Controller.
        -> The Controller processes the request, interacts with the Model to fetch or modify data.
        -> The Controller then sends back the appropriate response.

## Controller in MVC
    -> Purpose: Handles incoming HTTP requests, interacts with Models, and sends responses (usually JSON).
    -> Location: Stored in a dedicated controllers/ folder.
    -> Structure: Each controller file contains functions related to a specific resource (e.g., userController.js).
    -> Role in Flow: Router â†’ Controller â†’ Model â†’ Controller â†’ Response.

## View in MVC

    -> The View is responsible for displaying the UI.
    -> In traditional MVC, it handles Server-Side Rendering (SSR) by generating dynamic HTML or JSX.

    Common View Engines in Express:

        EJS (Embedded JavaScript):
            -> Syntax similar to HTML with <%= %> to insert dynamic data.
            -> Easy to integrate.

        Pug (formerly Jade):
            -> Minimalist template engine.
            -> Uses indentation instead of HTML tags.

        Handlebars:
            -> Logic-less templating.
            -> Uses {{ }} for dynamic data.

        react-express-view:
            -> Allows rendering React components (JSX) on the server.
            -> Great for React-based SSR apps.
        
## Models and Mongoose (ODM for MongoDB)

    What is Mongoose?
        -> Mongoose is an ODM (Object Data Modeling) library for MongoDB and Node.js.
        -> It allows you to define schemas and interact with MongoDB using models.

    Connection
        -> mongoose.connect(uri);

    Defining a Model
        -> const Model = mongoose.model("CollectionName", schemaObject);
        -> The CollectionName should be capitalized as a standard practice.
        -> Mongoose will:
            -> Automatically convert the name to lowercase
            -> Pluralize it (e.g., "User" becomes "users")

    Customize Pluralization
        -> mongoose.pluralize((word) => word); // disables pluralization

    Disable Auto Collection Creation
        -> mongoose.set("autoCreate", false);
        -> By default, Mongoose auto-creates collections even if no documents are inserted.
        -> Disabling this avoids unnecessary empty collections.

    Insert Data
        -> const Model = mongoose.model("CollectionName", schemaObject);
        -> await Model.insertOne({ name: "xyz" }); // âš ï¸ Use `Model.create()` instead
        -> Note: Model.insertOne() is not a Mongoose method â€” it's from native MongoDB.
        -> Use:
            await Model.create({ name: "xyz" });

    Schema vs Model
        -> Schema: Defines the shape of documents (application-level).
        -> Model: Provides the interface for interacting with the DB collection using that schema.

## Mongoose Query Behavior

    Connection Dependency
        -> No query is executed until Mongoose is connected to the database.
        -> Queries will be queued internally and executed once the connection is established
        -> mongoose.connect(uri);
        // Only after successful connection, queries will run

    Shared Connection
        -> A single Mongoose connection is reused across all files/modules.
        -> This means you typically connect once (e.g., in index.js or db.js) and then import the models in other files without reconnecting.

        // db.js
        mongoose.connect(uri);

        // userModel.js
        const User = mongoose.model("User", userSchema); // uses the same connection

##  Mongoose Schema Essentials

    -> Common Field Properties
        const userSchema = new mongoose.Schema({
        name: {
            type: String,
            required: [true, "Name is required"],
            minLength: [3, "Name must be at least 3 characters"],
            trim: true,
            lowercase: true,
        },
        age: {
            type: Number,
            min: [3, "Age must be at least 3"],
            required: function () {
            return this.name === "child"; // Conditional required
            },
            default: null
        },
        email: {
            type: String,
            match: [/^[\w-.]+@([\w-]+\.)+[\w-]{2,4}$/, "Invalid email format"],
            uppercase: true
        },
        });

    -> Other Schema Options
        Passed in the second argument of new mongoose.Schema():
        const schemaOptions = {
            strict: true,               // Ignores fields not defined in the schema
            timestamps: true,           // Adds createdAt and updatedAt
            versionKey: false,          // Removes __v field
            collection: "users",        // Custom collection name
            timeseries: {},             // For time-series collections (MongoDB >= 5.0)
        };
        const userSchema = new mongoose.Schema({ /* fields */ }, schemaOptions);

    -> ObjectId Reference
        userId: {
        type: mongoose.Schema.Types.ObjectId,
        ref: "User"
        }
    
## CRUD Operations Using Mongoose

    Setup First (Define Schema & Model)

        const mongoose = require("mongoose");
        const userSchema = new mongoose.Schema({
            name: String,
            email: String,
            age: Number
        });
        const User = mongoose.model("User", userSchema);
        module.exports = User;

    Create Operation

        -> insertOne()
        (Not native to Mongoose â€” use MongoDB driver or .create() instead)

        -> insertMany()
            Inserts an array of documents:
            await User.insertMany([
                { name: "John", email: "john@g.com" },
                { name: "Jane", email: "jane@g.com" }
            ]);

        -> create()
            Flexible method that handles one or many:

            await User.create({ name: "Mike", email: "mike@g.com" });
            await User.create([{ name: "A" }, { name: "B" }]);

        -> Using Instance & save()
            const user = new User({ name: "Sam", email: "sam@g.com" });
            await user.save(); // Saves to DB

    Read Operation

        -> Find one
            const user = await User.findOne({ email: "xyz@g.com" }).lean();
            Here, .lean() returns plain JS object (better performance, no Mongoose methods)

        -> Find all
            const users = await User.find().lean(); // Array of all users

        -> Find by ID
            const user = await User.findById("user_id").lean();

    Update Operation

        1. Inefficient Way (2 DB Calls)
            const user = await User.findOne({ email: "xyz@g.com" });
            user.age = 12;
            await user.save();

        2. Efficient Way (Single DB Call)
            const updatedUser = await User.findOneAndUpdate(
                { email: "xyz@gg.com" },
                { name: "Shizuka" },
                { new: true, runValidators: true }
            );

            new: true â†’ Returns the updated document
            runValidators: true â†’ Ensures validation is applied during update

    Delete Operation

        -> Delete one by condition
            await User.findOneAndDelete({ email: "xyz@g.com" });

        -> Delete by ID
            await User.findByIdAndDelete("user_id");

        -> Delete many
            await User.deleteMany({ age: { $lt: 18 } });

##  Thenable Objects

    -> A thenable is any object with a .then() method.
    -> It acts like a promise, but isnâ€™t necessarily created using Promise.
    -> Works with await and Promise.resolve().

    -> Example:
        const thenable = {
            then: (resolve, reject) => {
                resolve("Done!");
            }
        };
        await thenable; // Works like a promise

## What is a Mongoose Query?

    A Mongoose query is an object representing a database operation (e.g., find, update, delete). It allows you to build the query before executing it.

    -> Lazy Execution:
        A query doesn't run until you:
            await it
            Call .then()
            Use .exec()

        const query = User.find({ age: { $gt: 18 } }); // not yet executed
        const result = await query; // now it's executed

    -> Chaining:
        await User.find({ age: { $gte: 18 } })
                .select("name email")
                .limit(10)
                .sort({ name: 1 });

##  What is a Mongoose Document?

    -> A document is an instance of a Mongoose model, representing one record in the MongoDB collection.
    -> It is not a plain object â€” it inherits from Mongooseâ€™s Document class.
    -> Comes with built-in methods, schema validation, and middleware support.

    Key Characteristics
        -> Created using new Model({...}) or retrieved via query.
        -> Can interact with MongoDB using .save(), .deleteOne(), .updateOne(), etc.
        -> Supports validation, middleware, instance methods, and change tracking (.isModified()).

## Custom Validation in Mongoose

    Mongoose allows custom field validation using the validate option in schemas.

    Syntax:
        field: {
            type: String,
            validate: {
                validator: function (val) { return val.length > 3; },
                message: "Field must be longer than 3 characters."
            }
        }

    Alternate Shorthand:
        validate: [validatorFunction, "Error message"]

    Features:
        Return true if valid, false if invalid.
        Use props.value in error messages.
        Supports async validators (e.g., checking uniqueness in DB).

##  ref & populate in Mongoose

    ref: Used in schema to reference another model using ObjectId.
        author: { type: mongoose.Schema.Types.ObjectId, ref: "User" }

    populate(): Replaces the referenced ObjectId with the actual document.
        const post = await Post.find().populate("author");

    Used to create relationships (like foreign keys) between collections.

## Mongoose Virtuals

    -> Virtuals are computed properties in Mongoose documents, not stored in MongoDB.
    -> Common use: derive fullName from firstName + lastName.
    -> Mongoose adds an id virtual by default (string version of _id).

    Creating Virtuals
        -> Getter only
            schema.virtual('fullName').get(() => ...)
        -> Getter + Setter
            schema.virtual('fullName').get(() => ...).set(val => ...)

    Accessing Virtuals
        -> Enable in output
            doc.toJSON({ virtuals: true })
            doc.toObject({ virtuals: true })
        -> Schema-level access: schema.virtuals

    Virtuals & .lean()
        -> By default, virtuals do not work with .lean().
        -> To include them:
            Model.find().lean({ virtuals: true })
    
## Custom Instance Methods

    -> You can define document-level methods using the methods option in the schema:

        const userSchema = new mongoose.Schema({
        name: String
        }, {
            methods: {
                getSummary() {
                return `User: ${this.name}`;
                }
            }
        });

    -> this refers to the document
    -> Used like: user.getSummary()
    -> You can also add them manually:
        userSchema.methods.getSummary = function () { ... }

## Custom Static Methods

    -> You can define model-level methods using the statics option in the schema:

        const userSchema = new mongoose.Schema({
        email: String
        }, {
            statics: {
                async findByEmail(email) {
                return this.findOne({ email });
                }
            }
        });

    -> this refers to the model
    -> Used like: User.findByEmail("abc@example.com")
    -> You can also add them manually:
        userSchema.statics.findByEmail = async function (email) { ... }

## Mongoose Middleware (Hooks)

    Mongoose middlewares (hooks) are functions that run before (pre) or after (post) certain operations like saving, querying, inserting, or aggregating.

    Types of Middleware
        -> Document Middleware (save, validate, remove)
            Used to modify document data (e.g., hash passwords).

        -> Query Middleware (find, findOne, etc.)
            Modify or log queries (e.g., exclude inactive users).

        -> Model Middleware (insertMany)
            Modify documents before/after bulk insert.

        -> Aggregate Middleware (aggregate)
            Edit aggregation pipeline (e.g., exclude deleted docs).

## MongoDB Indexes

    Indexes in MongoDB are special data structures that improve the speed of read operations (like find, sort) by allowing MongoDB to quickly locate documents in a collection, just like an index in a book.

    Why Indexes?
        Without an index, MongoDB performs a collection scanâ€”checks every document. This is slow for large datasets.

    Usage:
        Create: db.collection.createIndex({ field: 1 })
        View: db.collection.getIndexes()
        Delete: db.collection.dropIndex({ field: 1 })

##  unique: true

    Used in schema to enforce unique values for a field.
        -> email: { type: String, unique: true }
        -> It creates a unique index.
        -> If duplicates exist, index creation fails.
        -> Clean duplicates before creating the index.

    Model.init()
        -> Ensures all indexes defined in the schema are created in the DB.
        -> Useful when auto-indexing is off.
        -> await User.init();

    autoIndex in Mongoose
        -> Controls whether Mongoose builds indexes automatically when the app starts.
        -> Schema Level:
            const schema = new Schema({}, { autoIndex: false });
        -> Connection Level:
            mongoose.connect(uri, { autoIndex: false });

## Mongoose Document Versioning

    -> Mongoose uses a __v field to track how many times a document has been modified.
    -> This version key is automatically incremented on .save().
    -> It helps with optimistic concurrency â€” preventing overwrites if another process updates the same document.
    -> You can enable it with { optimisticConcurrency: true } in the schema.
    -> Changes to arrays or subdocuments also increase __v.
    -> You can customize the version key or disable it using the versionKey option.

## Mongoose Built-in Errors

    CastError
        -> Occurs when a value can't be cast to the required type.
        -> Example:
            await User.findById("invalid-id"); // throws CastError

    ValidationError
        -> Happens when schema validation fails.
        -> Example:
            const user = new User({ email: "" });  
            await user.save(); // throws ValidationError for missing email

    ValidatorError
        -> Thrown for specific field validation failures.
        -> Example:
            email: {
                type: String,
                validate: v => v.includes("@") // if not, throws ValidatorError
            }

    DocumentNotFoundError
        -> Happens when .orFail() is used and no document is found.
        -> Example:
            await User.findById("someid").orFail(); // throws DocumentNotFoundError

    VersionError
        -> Occurs when there's a conflict in the __v version key during save (optimistic concurrency).
        -> Example:
            doc.__v = 2;  
            await doc.save(); // throws VersionError

    OverwriteModelError
        -> Thrown when trying to define a model with an existing name.
        -> Example:
            mongoose.model("User", schema);  
            mongoose.model("User", schema); // throws OverwriteModelError

    MissingSchemaError
        -> Occurs when you try to use a model that hasnâ€™t been defined yet.
        -> Example:
            mongoose.model("Unknown"); // throws MissingSchemaError


#-Discriminators in Mongoose.

A discriminator is a special type of Mongoose model that lets you create multiple models with different schemas but stored in the same MongoDB collection.
Itâ€™s useful when you have a base schema with shared fields, and child models with extra fields.
Think of it as inheritance in OOP for MongoDB documents.
Why Use Discriminators?
To avoid creating separate collections for similar types of documents.

#-To share common fields while allowing unique fields per model.
Useful in cases like:
Users with roles (Student, Teacher, Admin)
Payment methods (CreditCard, PayPal, UPI)
Products with categories (Book, Electronics, Clothing)
How Discriminators Work
You define a base schema (common fields).
You create discriminator models that extend the base schema with additional fields.
MongoDB stores everything in the same collection, and adds an internal field __t to distinguish the type.

 
          const mongoose = require("mongoose");
              const { Schema } = mongoose;
            // 1. Base Schema
              const UserSchema = new Schema({
                name: String,
             email: String,
               }, { discriminatorKey: "__t", collection: "users" });
// Base model
             #-Example: User with Roles
             
                 const User = mongoose.model("User", UserSchema);
// 2. Discriminator for Student

          const Student = User.discriminator("Student",
              new Schema({
    course: String,
    year: Number,
              })
          );
// 3. Discriminator for Teacher

            const Teacher = User.discriminator("Teacher",
             new Schema({
    subject: String,
    experience: Number,
         })
        );
// 4. Insert Example

         (async () => {
        await mongoose.connect("mongodb://127.0.0.1:27017/testdb");
            const s = await Student.create({ name: "Yash", email: "yash@test.com", course: "BCA", year: 3 });
             const t = await Teacher.create({ name: "Gupta", email: "gupta@test.com", subject: "Math", experience: 5 });
           console.log("Student:", s);
             console.log("Teacher:", t);
                       })();

How Data Looks in MongoDB


{
  "_id": "651b0f...",
  "name": "Yash",
  "email": "yash@test.com",
  "course": "BCA",
  "year": 3,
  "__t": "Student"
}
{
  "_id": "651b1a...",
  "name": "Gupta",
  "email": "gupta@test.com",
  "subject": "Math",
  "experience": 5,
  "__t": "Teacher"
}
 Querying
 
       const students = await Student.find();    // Only Student docs
       const teachers = await Teacher.find();    // Only Teacher docs
               const allUsers = await User.find();       // Both students & teachers


#-Model.discriminator() in Mongoose

     The Model.discriminator(name, schema, [options]) method is used to create a discriminator model based on an existing base model.
      When you use Mongoose discriminators, all the documents (base + discriminators) are stored in the base modelâ€™s collection.
       Event + Discriminators
     Base Model
       const mongoose = require("mongoose");
           const { Schema } = mongoose;

// Base schema for Event

                 const eventSchema = new Schema({
               title: String,
               date: Date
           }, { discriminatorKey: "__t", collection: "events" });
             // Base model
          const Event = mongoose.model("Event", eventSchema);

Discriminators

             // Conference event discriminator
                 const Conference = Event.discriminator("Conference",
                     new Schema({
                      location: String,
                speakers: [String]
            })
                  );

         // Webinar event discriminator
             const Webinar = Event.discriminator("Webinar",
            new Schema({
    url: String,
      host: String
        })
      );
         Saving Documents
              js
          await Conference.create({
           title: "AI Summit",
            date: new Date(),
           location: "New Delhi",
             speakers: ["Yash", "Gupta"]
                       });
              await Webinar.create({
           title: "MongoDB Deep Dive",
              date: new Date(),
               url: "https://meet.example.com",
                 host: "SuPrazo"
         });
         ðŸ“Œ How It Looks in MongoDB (events collection)

               {
           "_id": "652abcd...",
               "title": "AI Summit",
           "date": "2025-10-02T00:00:00Z",
          "location": "New Delhi",
                    "speakers": ["Yash", "Gupta"],
             "__t": "Conference"
      }
       {
            "_id": "652abce...",
             "title": "MongoDB Deep Dive",
           "date": "2025-10-02T00:00:00Z",
            "url": "https://meet.example.com",
            "host": "SuPrazo",
               "__t": "Webinar"
              }
ðŸ‘‰ Both documents are stored in the same events collection, but the __t discriminator key tells Mongoose what subtype it is (Conference or Webinar).
ðŸ“Œ Querying

          const allEvents = await Event.find();       // returns both Conference + Webinar
           const conferences = await Conference.find(); // only conferences
                   const webinars = await Webinar.find();


 In short:
Discriminators always save documents into the base modelâ€™s collection.
The discriminator type is tracked using the __t field (or your custom discriminator k
What is a Discriminator Key?
A discriminator key is the field that Mongoose uses to differentiate between documents of different discriminator models stored in the same base collection.

By default, this field is named __t.

        The value of the discriminator key is the name you gave to the discriminator model (e.g., "Student", "Teacher", "Webinar").
              const mongoose = require("mongoose");
            const { Schema } = mongoose;
          const options = { discriminatorKey: "kind", collection: "events" };
              const eventSchema = new Schema({
           title: String,
            date: Date
          }, options);
             const Event = mongoose.model("Event", eventSchema);
             Discriminators
           js

            const Webinar = Event.discriminator("Webinar",
             new Schema({
    url: String,
    host: String
        })
        );
             const Conference = Event.discriminator("Conference",
             new Schema({
    location: String,
    speakers: [String]
            })
       );
ðŸ“Œ  Documents in MongoDB

       If you save:
       await Webinar.create({ title: "MongoDB 101", date: new Date(), url: "zoom.com/meet", host: "Yash" });
      await Conference.create({ title: "Tech Summit", date: new Date(), location: "Delhi", speakers: ["Alice", "Bob"] });
          Stored documents in events collection look like:

        {
        "_id": "652abc1...",
       "title": "MongoDB 101",
          "date": "2025-10-02T00:00:00Z",
          "url": "zoom.com/meet",
             "host": "Yash",
             "kind": "Webinar"
            }
              {
           "_id": "652abc2...",
              "title": "Tech Summit",
              "date": "2025-10-02T00:00:00Z",
               "location": "Delhi",
                   "speakers": ["Alice", "Bob"],
                       "kind": "Conference"
          }
ðŸ‘‰  Notice here the discriminator key is "kind", not the default __t.
ðŸ“Œ Changing the Discriminator Key
       You can override the default like this:

        const eventSchema = new Schema({
        title: String,
         date: Date
       }, { discriminatorKey: "eventType" });
       Now MongoDB will store:
       json

      {
        "title": "AI Summit",
       "date": "2025-10-02",
       "eventType": "Conference"
        }
ðŸ“Œ                Key Points about Discriminator Keys
          Default is __t.
       Can be customized via { discriminatorKey: "customField" } in the schema options.
        The value stored is the name of the discriminator model.
       This field is automatically added by Mongoose when saving discriminator docs.
       Useful for queries (e.g., Event.find({ kind: "Webinar" })).
      âœ… In short:
   Discriminator keys are the â€œlabelsâ€ that tell MongoDB which subtype a document belongs to when youâ€™re using discriminators. Theyâ€™re essential because all discriminators share the same collection.


       Use discriminatorKey in schema options to define a custom key name.
     To reclassify a document, update the key field directly (eventType).
       If you rename the discriminator key, migrate old docs accordingly.


                                                              
